---
permalink: /
title: " "
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Hello! I am Assistant Professor at [Université Paris Cité](https://u-paris.fr/) and [LPSM](https://www.lpsm.paris/equipes/stat/index). I am mostly interested in optimization and gradient methods in machine learning contexts.


Previously, I was a postdoctoral researcher in the team [DAO](https://dao-ljk.imag.fr/), at LJK, Université Grenoble Alpes where I worked on statistical aspects of Wasserstein distributionally robust models. I completed my PhD (October 2023) at Toulouse School of Economics (TSE) and ANITI, supervized by Jérôme Bolte and Edouard Pauwels. I worked on stochastic, nonsmooth and nonconvex optimization in machine learning. Some questions I studied there included convergence guarantees when using automatic differentiation in stochastic algorithms (e.g. SGD in deep learning), and nonsmooth implicit differentiation applied to optimization layers and hyperparameter selection.


\[[CV (fr)](https://ntamle.github.io/cv_tam_le.pdf)\].

## Pre-prints

* Inexact subgradient methods for semialgebraic functions, J. Bolte, T. Le, E. Moulines and E. Pauwels, \[[preprint](https://arxiv.org/abs/2404.19517)\].
  
## Publications

* Universal Generalization Guarantees for Wasserstein Distributionally Robust Models, T. Le and J. Malick,  ICLR 2025 (Spotlight) \[[paper](https://arxiv.org/pdf/2402.11981)\]. 
* Subgradient sampling for nonsmooth nonconvex minimization, J. Bolte, T. Le, E. Pauwels, SIAM Journal on Optimization 2023 \[[paper](https://arxiv.org/abs/2202.13744)\]
* Nonsmooth nonconvex stochastic heavy ball, to appear in Journal of Optimization Theory and Applications 2024 \[[paper](https://arxiv.org/abs/2304.13328)\]
* Nonsmooth Implicit Differentiation for Machine Learning and Optimization J. Bolte, T. Le, E. Pauwels, A. Silveti-Falls, NeurIPS 2021. \[[paper](https://arxiv.org/abs/2106.04350)\]



## Thesis
Nonsmooth calculus and optimization for machine learning: first-order sampling and implicit differentiation, T. Le, PhD Thesis, 2023. Advised by Jérôme Bolte and Edouard Pauwels. The defence committee was composed of Gersende Fort (President), Damek Davis and Jérôme Malick (reviewers), Pascal Bianchi and Eric Moulines (examiners) \[[manuscript](https://ntamle.github.io/files/manuscript.pdf)\] \[[slides](https://ntamle.github.io/files/slides.pdf)\] 



Awarded the [PGMO PhD Award 2024](https://www.fondation-hadamard.fr/en/our-programs/thematic-programs/pgmohome/phd-awards)! 


## Communications

**  Inexact subgradient methods for semialgebraic functions, ICCOPT 2025, Los Angeles


** Talk for the PGMO PhD Prize 2024 \[[slides](https://ntamle.github.io/files/pgmo_phd_prize_slides.pdf)\]



** Generalization guarantees of Wasserstein robust models

* LAMSADE-MILES seminar - Université Paris Dauphine, Paris (talk), 2024
* Journées SMAI-MODE Lyon (talk), 2024


**  Nonsmooth nonconvex stochastic heavy ball,  Mathematical Optimization research seminar, University of Tübingen (online talk), 2024.

** Nonsmooth implicit differentiation in machine learning and optimization

* ANITI-PRAIRIE workshop, Toulouse (poster), 2023.
* Neurips (online poster), Neurips Paris event (poster), 2021.
* Stat-Eco-ML seminar, CREST (talk), 2021.

  
** Subgradient sampling in nonconvex minimization (talks).

* EUROPT, Budapest 2023.
* SIAM Conference on optimization, Seattle 2023. 
* PGMO Days, Paris 2022.
* GdR MOA Days, Nice 2022.
* Mathematical Optimization research seminar, University of Tübingen (online), 2022.
* ICCOPT, Bethlehem (Pennsylvania) 2022.
* French-German days Inria, Le Chesnay-Rocquencourt 2021.
* Toulouse School of Economics, PhD students seminar.

 

## Teaching

In 2024-2025, I gave tutorials (sessions dedicated to guided exercises) and hands on sessions (TD et TP) to Bachelor students  at Université Paris Cité

* Numerical methods (L3 Maths, MIASHS)
* Convex optimization (L3 Maths, MIASHS)
* Statistics and sampling methods (L3 Maths-Enseignement)
* Ordinary differential equations for biology (L2 Biologie)

Between 2020 and 2023, I gave several tutorials at Université Toulouse 1 Capitole and Toulouse School of Economics

* R for data science and statistics (M1 Data science for social sciences)
* Optimization for big data (M1 Data science for social sciences)
* PyTorch tutorial for Deep Learning (M2 Data science for social sciences)
* Optimization (L3 Economie)
* Analysis and Optimization, (L3 Economie et Mathématiques)
* Support course in mathematics (L1)
* Mathematics, Undergraduate (L1 Economie et Mathématiques, L1 Economie Gestion, L1 Gestion)
* Descriptive statistics (L1)


## Professional services

* Co-organizing the statistics seminar at LPSM in 2024-2025.
* I served as a reviewer for AISTATS (2023), ICLR (2025), SIAM Journal on optimization and Mathematical programming.

## Education
* Ph.D. in Applied Mathematics, Toulouse School of Economics, 2020 - 2023
* MSc in Machine Learning and Computer Vision, ENS Paris-Saclay, 2019 - 2020
* MSc in Statistics and Machine Learning, ENSAE Paris 2017 - 2020





